{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intent_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8rnuJ1ZN8_y",
        "outputId": "8b7e76d3-f628-4c5c-efc5-daf7798fd9cb"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DYPaubIBGry",
        "outputId": "c7dee860-e0dc-4704-c488-c83d524a5ad0"
      },
      "source": [
        "!unzip slack_assist_data.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  slack_assist_data.zip\n",
            "   creating: slack_assist_data/\n",
            "  inflating: slack_assist_data/dialogues.tsv  \n",
            "  inflating: slack_assist_data/tagged_posts.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GcE1N4456pH"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyt7lTn65922"
      },
      "source": [
        "num_words = 250000\n",
        "oov_token = '<oov>'\n",
        "train_size = 0.8\n",
        "maxlen = 20\n",
        "padding = 'pre'\n",
        "truncating = 'pre'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ECtC-z4Ini"
      },
      "source": [
        "def text_prepare(text):\n",
        "    \"\"\"Preform tokenization simple preprocessing\"\"\"\n",
        "    \n",
        "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "    \n",
        "    text = text.lower()\n",
        "    text = replace_by_space_re.sub(' ', text)\n",
        "    text = bad_symbols_re.sub('', text)\n",
        "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
        "    return str(text.strip())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3GbXAP9OIM7"
      },
      "source": [
        "dialouges_df = pd.read_csv('/content/slack_assist_data/dialogues.tsv', sep='\\t')\n",
        "dialouges_df['label'] = 0\n",
        "dialouges_df = dialouges_df[['text', 'label']]\n",
        "tagged_post_df = pd.read_csv('/content/slack_assist_data/tagged_posts.tsv', sep='\\t')\n",
        "tagged_post_df['label'] = 1\n",
        "tagged_post_df = tagged_post_df[['title', 'label']]\n",
        "tagged_post_df = tagged_post_df.rename(columns={'title':'text'})\n",
        "all_df = pd.concat([dialouges_df, tagged_post_df])\n",
        "all_df = all_df.sample(frac=1).reset_index(drop=True)\n",
        "all_df['text'] = all_df['text'].apply(text_prepare)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIGOWcAOVpCe"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(list(all_df['text'].values))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LyN8AIgZhA9"
      },
      "source": [
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMm4yagB-Vb4"
      },
      "source": [
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYoxE4_zBGNA"
      },
      "source": [
        "#Define Train test data\n",
        "msk = np.random.rand(len(all_df)) <= train_size\n",
        "train_data = all_df[msk]\n",
        "test_data = all_df[~msk]\n",
        "train_sentence = train_data['text'].values\n",
        "train_label = train_data['label'].values\n",
        "test_sentences = test_data['text'].values\n",
        "test_label = test_data['label'].values"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3udDE4_NDFtM"
      },
      "source": [
        "#Create data to sequence\n",
        "train_sequence = tokenizer.texts_to_sequences(train_sentence)\n",
        "train_padded = pad_sequences(train_sequence, maxlen=maxlen, padding=padding, truncating=truncating)\n",
        "test_sequence = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequence, maxlen=maxlen, padding=padding, truncating=truncating)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6c7Vvb7DvMV"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(128, activation='relu', input_shape=(20,)),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.Dense(256, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgiE4TiR-HK9",
        "outputId": "4431025f-ac73-4265-c29b-8094df810fc3"
      },
      "source": [
        "model.fit(train_padded, train_label, validation_data=(test_padded, test_label), batch_size=64, epochs=10)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "29880/29880 [==============================] - 81s 3ms/step - loss: 15.6205 - accuracy: 0.8892 - val_loss: 0.3078 - val_accuracy: 0.9140\n",
            "Epoch 2/10\n",
            "29880/29880 [==============================] - 81s 3ms/step - loss: 0.6220 - accuracy: 0.9120 - val_loss: 0.3432 - val_accuracy: 0.9178\n",
            "Epoch 3/10\n",
            "29880/29880 [==============================] - 82s 3ms/step - loss: 0.6859 - accuracy: 0.9132 - val_loss: 0.3150 - val_accuracy: 0.9162\n",
            "Epoch 4/10\n",
            "29880/29880 [==============================] - 82s 3ms/step - loss: 0.8718 - accuracy: 0.9126 - val_loss: 0.3096 - val_accuracy: 0.9110\n",
            "Epoch 5/10\n",
            "29880/29880 [==============================] - 81s 3ms/step - loss: 0.8241 - accuracy: 0.9096 - val_loss: 0.3203 - val_accuracy: 0.9115\n",
            "Epoch 6/10\n",
            "29880/29880 [==============================] - 82s 3ms/step - loss: 0.8230 - accuracy: 0.9104 - val_loss: 0.3213 - val_accuracy: 0.9104\n",
            "Epoch 7/10\n",
            "29880/29880 [==============================] - 82s 3ms/step - loss: 0.9228 - accuracy: 0.9093 - val_loss: 0.3092 - val_accuracy: 0.9110\n",
            "Epoch 8/10\n",
            "29880/29880 [==============================] - 81s 3ms/step - loss: 0.9694 - accuracy: 0.9096 - val_loss: 0.6947 - val_accuracy: 0.9025\n",
            "Epoch 9/10\n",
            "29880/29880 [==============================] - 81s 3ms/step - loss: 0.9768 - accuracy: 0.9098 - val_loss: 0.3399 - val_accuracy: 0.9094\n",
            "Epoch 10/10\n",
            "29880/29880 [==============================] - 82s 3ms/step - loss: 0.6830 - accuracy: 0.9095 - val_loss: 0.3143 - val_accuracy: 0.9107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f72f6031ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GejauhV1GFDS",
        "outputId": "b19129b3-18ad-401f-948c-c3fd358788c0"
      },
      "source": [
        "#Validation f1_score\n",
        "prediction = model.predict_classes(test_padded)\n",
        "f1_score(test_label, prediction)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9531518887391676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPzZVU8hFYeU"
      },
      "source": [
        "#save Model\n",
        "model.save('intent_classifier.h5')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZNytVc8NRog"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}