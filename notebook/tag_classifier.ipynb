{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tag_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8rnuJ1ZN8_y",
        "outputId": "042e3cb2-7df4-4622-f7a8-a56dbe70aa2e"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DYPaubIBGry",
        "outputId": "7c024bdb-c0c3-495e-814f-903f1e4e2ec0"
      },
      "source": [
        "!unzip slack_assist_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open slack_assist_data.zip, slack_assist_data.zip.zip or slack_assist_data.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GcE1N4456pH"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyt7lTn65922"
      },
      "source": [
        "num_words = 50000\n",
        "oov_token = '<oov>'\n",
        "train_size = 0.8\n",
        "maxlen = 20\n",
        "padding = 'pre'\n",
        "truncating = 'pre'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ECtC-z4Ini"
      },
      "source": [
        "def text_prepare(text):\n",
        "    \"\"\"Preform tokenization simple preprocessing\"\"\"\n",
        "    \n",
        "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "    \n",
        "    text = text.lower()\n",
        "    text = replace_by_space_re.sub(' ', text)\n",
        "    text = bad_symbols_re.sub('', text)\n",
        "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
        "    return str(text.strip())\n",
        "def map_tag(tag):\n",
        "  return label_dict[tag]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka46tkPYSlXW"
      },
      "source": [
        "tagged_post_df = pd.read_csv('/content/tagged_posts.tsv', sep='\\t')\n",
        "#Define label dictionary\n",
        "label_dict = {}\n",
        "for step, tag in enumerate(tagged_post_df['tag'].unique()):\n",
        "  label_dict[tag] = step\n",
        "tagged_post_df['label'] = tagged_post_df['tag'].apply(map_tag)\n",
        "tagged_post_df = tagged_post_df[['title', 'label']]\n",
        "tagged_post_df['title'] = tagged_post_df['title'].apply(text_prepare)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIGOWcAOVpCe"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(list(tagged_post_df['title'].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LyN8AIgZhA9"
      },
      "source": [
        "with open('tokenizer_tag.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkW5O5EiPVzR"
      },
      "source": [
        "with open('label_dict.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMm4yagB-Vb4"
      },
      "source": [
        "with open('tokenizer_tag.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYoxE4_zBGNA"
      },
      "source": [
        "#Define Train test data\n",
        "msk = np.random.rand(len(tagged_post_df)) <= train_size\n",
        "train_data = tagged_post_df[msk]\n",
        "test_data = tagged_post_df[~msk]\n",
        "train_sentence = train_data['title'].values\n",
        "train_label = train_data['label'].values\n",
        "train_label = tf.keras.utils.to_categorical(train_label, len(label_dict.keys()))\n",
        "test_sentences = test_data['title'].values\n",
        "test_label = test_data['label'].values\n",
        "test_label = tf.keras.utils.to_categorical(test_label, len(label_dict.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3udDE4_NDFtM"
      },
      "source": [
        "#Create data to sequence\n",
        "train_sequence = tokenizer.texts_to_sequences(train_sentence)\n",
        "train_padded = pad_sequences(train_sequence, maxlen=maxlen, padding=padding, truncating=truncating)\n",
        "test_sequence = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequence, maxlen=maxlen, padding=padding, truncating=truncating)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6c7Vvb7DvMV"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=num_words+1, output_dim=50, input_length=maxlen),\n",
        "                                    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                                    tf.keras.layers.Dense(256, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgiE4TiR-HK9",
        "outputId": "66c8aa63-6a5a-471d-c28d-fc1ffa83a705"
      },
      "source": [
        "history = model.fit(train_padded, train_label, validation_data=(test_padded, test_label), batch_size=256, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6787/6787 [==============================] - 81s 11ms/step - loss: 0.1707 - accuracy: 0.6364 - val_loss: 0.0975 - val_accuracy: 0.8028\n",
            "Epoch 2/10\n",
            "6787/6787 [==============================] - 76s 11ms/step - loss: 0.0965 - accuracy: 0.8063 - val_loss: 0.0949 - val_accuracy: 0.8082\n",
            "Epoch 3/10\n",
            "6787/6787 [==============================] - 76s 11ms/step - loss: 0.0939 - accuracy: 0.8117 - val_loss: 0.0939 - val_accuracy: 0.8115\n",
            "Epoch 4/10\n",
            "6787/6787 [==============================] - 76s 11ms/step - loss: 0.0926 - accuracy: 0.8155 - val_loss: 0.0925 - val_accuracy: 0.8146\n",
            "Epoch 5/10\n",
            "6787/6787 [==============================] - 77s 11ms/step - loss: 0.0916 - accuracy: 0.8180 - val_loss: 0.0925 - val_accuracy: 0.8142\n",
            "Epoch 6/10\n",
            "6787/6787 [==============================] - 76s 11ms/step - loss: 0.0908 - accuracy: 0.8199 - val_loss: 0.0915 - val_accuracy: 0.8174\n",
            "Epoch 7/10\n",
            "6787/6787 [==============================] - 76s 11ms/step - loss: 0.0904 - accuracy: 0.8213 - val_loss: 0.0916 - val_accuracy: 0.8178\n",
            "Epoch 8/10\n",
            "6787/6787 [==============================] - 76s 11ms/step - loss: 0.0899 - accuracy: 0.8232 - val_loss: 0.0911 - val_accuracy: 0.8189\n",
            "Epoch 9/10\n",
            "6787/6787 [==============================] - 77s 11ms/step - loss: 0.0894 - accuracy: 0.8250 - val_loss: 0.0908 - val_accuracy: 0.8196\n",
            "Epoch 10/10\n",
            "6787/6787 [==============================] - 76s 11ms/step - loss: 0.0890 - accuracy: 0.8258 - val_loss: 0.0910 - val_accuracy: 0.8197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPzZVU8hFYeU"
      },
      "source": [
        "#save Model\n",
        "model.save('tag_classifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EI8ZeEKce0w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}